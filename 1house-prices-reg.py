# -*- coding: utf-8 -*-
"""ml1-LinearReg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y7oBLa9CTIoppc7clvH0Uf_arWY-kx6G
"""

#==============================================================================
# Emily Chen
# CS6375 Machine Learning
# Assignment 1 - Linear Regression
# Task: Perform linear regression analysis to predict housing prices based on housing prices in Melbourne.
# Kaggle Dataset: https://www.kaggle.com/datasets/anthonypino/melbourne-housing-market?select=Melbourne_housing_FULL.csv
#==============================================================================
# Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import sklearn
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import SGDRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from datetime import datetime as dt
import matplotlib.pyplot as plt
#from sklearn.preprocessing import OneHotEncoder

pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
np.random.seed(0)

#==============================================================================
# Obtaining the dataset
#==============================================================================
# Grab dataset link from uploading to github
melbournedf = pd.read_csv("https://raw.githubusercontent.com/emilc-jpg/Datasets/main/Melbourne_housing_FULL.csv")
display(melbournedf.head())

# This dataset had 21 attributes: 
# Suburb, Address, # Rooms, Type, Price, Method, SellerG, Date, Distance, Postcode, Bedroom2, Bathroom, Car, Landsize, 
# BuildingArea,YearBuilt, CouncilArea, Lattitude, Longitude, Regionname, and Propertycount
print(melbournedf.keys())
print(len(melbournedf))

#==============================================================================
# Data Preprocessing
#==============================================================================
# Check attributes with low correlation with price
display(melbournedf.corr())

# Remove attributes with no price label
melbournedf = melbournedf[melbournedf['Price'].notna()] # 34857 -> 27247
#---------------
# Reduce the number of attributes that would not improve the performance of our learning task 
melbournedf = melbournedf.drop("Rooms", axis=1)         # Removed to maintain linear independence betw bathrooms and bedrooms
melbournedf = melbournedf.drop("Suburb", axis=1)        # Too varied to be meaningful
melbournedf = melbournedf.drop("Address", axis=1)       # Lacking in geolocation capabilities for now
melbournedf = melbournedf.drop("Type", axis=1)          # In the future, could incorporate one-hot encoding for type
melbournedf = melbournedf.drop("Postcode", axis=1)
melbournedf = melbournedf.drop("SellerG", axis=1)
melbournedf = melbournedf.drop("CouncilArea", axis=1)
melbournedf = melbournedf.drop("Lattitude", axis=1)
melbournedf = melbournedf.drop("Longtitude", axis=1)
melbournedf = melbournedf.drop("Regionname", axis=1)
melbournedf = melbournedf.drop("Propertycount", axis=1)
# I kept attributes even with low correlation coefficients beecause of base assumptions of influence

#display(melbournedf.head())
#---------------
# Keep only houses that have been sold (S - sold, SP - sold prior, SA - sold after auction)
sold = ["S", "SP", "SA"] 
melbournedf = melbournedf[melbournedf['Method'].isin(sold)]   # 27427 -> 21308
melbournedf = melbournedf.drop("Method", axis=1)    # Method only for filtering
#---------------
# We want to keep date because it could be useful in predicting house pricing over time
# Convert date to numerical/ordinal to be able to use
new_date_list = []
date_list = melbournedf['Date'].to_numpy()

for x in range(len(date_list)):
  date_new = dt.strptime(date_list[x], '%M/%d/%Y')    # Format from mm/dd/yy  
  date_ord = date_new.toordinal()
  new_date_list.append(date_ord)

melbournedf["Date-Ordinal"] = new_date_list           # Add recoded date, delete old
melbournedf = melbournedf.drop("Date", axis=1)
#display(melbournedf.head())
#---------------
# Drop rows that have NaN values (now that we only have attributes that we are interested in)
melbournedf = melbournedf.dropna()        # 21308 -> 6963

display(melbournedf.head(10))
print(melbournedf.keys())         # Now we only have 10 feature attributes left + 1 predicted (price)
print(len(melbournedf))

#==============================================================================
# Analyzing the Dataset
#==============================================================================
display(melbournedf.describe())
correlation_matrix = melbournedf.corr()
display(correlation_matrix)

sns.heatmap(data=correlation_matrix, annot=True)

# Analyze a couple of features in detail
sns.displot(melbournedf["Price"])
sns.displot(melbournedf["Bedroom2"])
sns.displot(melbournedf["Bathroom"])
sns.displot(melbournedf["BuildingArea"])
sns.displot(melbournedf["YearBuilt"])
sns.displot(melbournedf["Date-Ordinal"])
sns.displot(melbournedf["Distance"])
# sns.pairplot(data = melbournedf)

#==============================================================================
# Split dataset into training/test, shuffle, normalize
#==============================================================================
# Split into X feature attributes and y prediction label
X = melbournedf[['Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Date-Ordinal']]
y = melbournedf[['Price']]

# Normalize data using standard scaling
s = StandardScaler()
X = pd.DataFrame(s.fit(X).fit_transform(X))
y = pd.DataFrame(s.fit(y).fit_transform(y))
print(X)
print(y)

# Split into taining and test sets, 80/20 and shuffle
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

#==============================================================================
# OLS Linear Regression
# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
#==============================================================================
# Create the model
OLSreg_model = LinearRegression()
OLSreg_model.fit(X_train, y_train)

# Evaluate training metrics
y_train_pred = OLSreg_model.predict(X_train)

rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))
r2 = r2_score(y_train, y_train_pred)

print("The model performance for training set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))
print("\n")


# Model evaluation for testing set
y_test_pred = OLSreg_model.predict(X_test)

rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))
r2 = r2_score(y_test, y_test_pred)

print("The model performance for test set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))
print("\n")


# Plot
plt.scatter(OLSreg_model.predict(X_train), y_train)
plt.xlabel('y_pred')
plt.ylabel('y_true')
plt.show()

plt.scatter(OLSreg_model.predict(X_test), y_test)
plt.xlabel('y_pred')
plt.ylabel('y_true')
plt.show()

#==============================================================================
# SGD Linear Regression
# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html
#==============================================================================
# Create the model
SGDreg_model = SGDRegressor(max_iter = 10000, learning_rate = "constant", eta0 = 0.003, alpha = 0.2)
SGDreg_model.fit(X_train, y_train) 


# Evaluate training metrics
y_train_pred = SGDreg_model.predict(X_train)


rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))
r2 = r2_score(y_train, y_train_pred)

print("The model performance for training set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))
print("\n")

# Model evaluation for testing set
y_test_pred = SGDreg_model.predict(X_test)

rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))
r2 = r2_score(y_test, y_test_pred)

print("The model performance for test set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))
print("\n")


# Plot
plt.scatter(SGDreg_model.predict(X_train), y_train)
plt.xlabel('y_pred')
plt.ylabel('y_true')
plt.show()

plt.scatter(SGDreg_model.predict(X_test), y_test)
plt.xlabel('y_pred')
plt.ylabel('y_true')
plt.show()
